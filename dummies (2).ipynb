{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import linear_model\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\npd.options.display.max_columns = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # 1. EDA"},{"metadata":{},"cell_type":"markdown","source":"### 1.1 Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/mlbio1/sample_submission.csv')\ntest = pd.read_csv('/kaggle/input/mlbio1/test.csv')\ntrain = pd.read_csv('/kaggle/input/mlbio1/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"stroke\"].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',shadow=True)\nplt.legend()\nplt.title('');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Classes are imbalanced"},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Working with missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = (train.count() / len(train)).drop(\"stroke\").sort_values().values\nind = np.arange(len(train_data))\nwidth = 0.35\nfig, axes = plt.subplots(1,1,figsize=(10, 7), dpi=100)\ntr = axes.bar(ind, train_data, width, color='royalblue')\n\ntest_data = (test.count() / len(test)).sort_values().values\ntt = axes.bar(ind+width, test_data, width, color='seagreen')\n\naxes.set_ylabel('Amount of data available');\naxes.set_xticks(ind + width / 2)\naxes.set_xticklabels((train.count() / len(train)).sort_values().index, rotation=40)\naxes.legend([tr, tt], ['Train', 'Test']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#counts of nan\nfor i in train.columns:\n    print(i, (pd.isnull(train[i])).sum() )\ntrain[train['smoking_status'].isnull()== False]\ntrain[\"smoking_status\"].unique()\n\n# fill with mean\nmean_bmi = train['bmi'].mean()\ntrain['bmi'] = train['bmi'].fillna(mean_bmi)\ntest['bmi'] = test['bmi'].fillna(mean_bmi)\n\ntrain['smoking_status'] = train['smoking_status'].fillna('nan')\ntest['smoking_status'] = test['smoking_status'].fillna('nan')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3 Categorial data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_d = pd.get_dummies(train)\ntest_d = pd.get_dummies(test)\nall_feat = train_d.columns\ntrain_d.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.4 Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"ticks\", palette=\"pastel\",rc={'figure.figsize':(11.7,8.27)})\ntips = train_d[[\"age\",\"avg_glucose_level\",\"bmi\"]]\n\nsns.boxplot(orient = \"h\", palette=[\"b\"], data=tips, fliersize = 3)\nsns.despine(offset=10, trim=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Outliers in \"bmi\" and \"avg_glucose\" are excluded (each value, which bigger than 2*the arithmetic mean)\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_no_outliers = train_d[train_d[\"bmi\"]<2*train_d[\"bmi\"].mean()]\ntrain_no_outliers = train_no_outliers[train_no_outliers[\"avg_glucose_level\"]<2*train_no_outliers[\"avg_glucose_level\"].mean()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2 Cross validation strategy"},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC metric for binary classification with imbalanced classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_cross_validation_for_roc_auc( clf, X, y ,cv=5):\n    X = np.array(X.copy())\n    y = np.array(y.copy())\n    kf = KFold(n_splits=cv)\n    kf.get_n_splits(X)\n    scores = []\n    for train_index, test_index in kf.split(X):\n        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        \n        clf.fit(X_train, y_train)\n        prediction_on_this_fold = clf.predict_proba(X_test)[:,1]\n        score = roc_auc_score(y_score=prediction_on_this_fold, y_true=y_test)\n        scores.append(score)\n    \n    return scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3 Feature analysis"},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Correlation Between The Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"#all features\nall_features = train_no_outliers.columns\nsns.heatmap(train_no_outliers[all_features].corr(),annot=True,cmap='RdYlGn',linewidths=0.1)\nfig=plt.gcf()\nfig.set_size_inches(22.5,16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Feature selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb =   LGBMClassifier(n_estimators=185, max_depth=3,boosting_type='dart',\n                       num_leaves=6,learning_rate=0.15,reg_lambda=0.46)\nfeatures_scores = {}\nfor f in all_features:\n    scores = my_cross_validation_for_roc_auc(lgb, train_no_outliers[[f]] , train_no_outliers['stroke'])\n    print(f,  np.mean(scores))\n    features_scores[f] = np.mean(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By Greedy algorithm 9 features were chosen (f3)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# final features\nf3 = [ 'age', 'hypertension', 'heart_disease', 'avg_glucose_level',\n       'bmi', 'ever_married_No', 'ever_married_Yes', 'work_type_Self-employed',\n      'work_type_children']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Algorithms"},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Linear classifier with stochastic gradient descent and log-loss function \nSGDClassifier(max_iter=5000,  loss='log', penalty = 'l1')\n#### It shows Public score = 0.85150\n#### CV scores by fold 0.8062307247329275, 0.7490840031621402, 0.8063909708107497, 0.8094846798391414, 0.8381774540714938"},{"metadata":{},"cell_type":"markdown","source":"### 4.2 LightGBM classifier with traditional Gradient Boosting Decision Tree\nLGBMClassifier(n_estimators=100, max_depth=4)\n#### It shows Public score = 0.86024\n#### CV scores by fold 0.8482923097460542, 0.8525358384287318, 0.8578461989046974, 0.8444127652098369, 0.8442989601929999"},{"metadata":{},"cell_type":"markdown","source":"### 4.3 LightGBM classifier with Dropouts meet Multiple Additive Regression Trees\nLGBMClassifier(n_estimators=185, max_depth=3,boosting_type='dart',num_leaves=6,learning_rate=0.15,reg_lambda=0.46)\n#### It shows Public score = 0.87502\n#### CV scores by fold 0.8573062163538484, 0.8647515900122407, 0.8579354378082416, 0.8668245957359151, 0.8584210026934971"},{"metadata":{},"cell_type":"markdown","source":"GBM Classifier from LightGBM library with boosting type ‘dart’(Dropouts meet Multiple Additive Regression Trees) shows the best score"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb =   LGBMClassifier(n_estimators=185, max_depth=3,boosting_type='dart',\n                       num_leaves=6,learning_rate=0.15,reg_lambda=0.46)\nscores = my_cross_validation_for_roc_auc(lgb, train_no_outliers[f3] , train_no_outliers['stroke'])\nprint (scores, np.mean(scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.4 CV score and Public Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"folds_pred = [0.8062307247329275, 0.7490840031621402, 0.8063909708107497, 0.8094846798391414, 0.8381774540714938]\nfolds = [1,2,3,4,5]\n#d = {'Score': folds_pred, 'Fold': folds}\n#df = pd.DataFrame(data=d)\nplt.figure(figsize=(10,8), dpi= 80, facecolor='w', edgecolor='w')\nplt.scatter(folds,folds_pred,color = 'g')\nplt.axhline(y=0.85150, color='r', linestyle='-',label = \"Public score\")\nplt.xlabel('Fold')\nplt.ylabel('Public score')\nplt.title('SGDClassifier with log-loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds_pred = [0.8482923097460542, 0.8525358384287318, 0.8578461989046974, 0.8444127652098369, 0.8442989601929999]\nfolds = [1,2,3,4,5]\n#d = {'Score': folds_pred, 'Fold': folds}\n#df = pd.DataFrame(data=d)\nplt.figure(figsize=(10,8), dpi= 80, facecolor='w', edgecolor='w')\nplt.scatter(folds,folds_pred,color = 'g')\nplt.axhline(y= 0.86024, color='r', linestyle='-',label = \"Public score\")\nplt.xlabel('Fold')\nplt.ylabel('Public score')\nplt.title('LGBMClassifier with \"gbdt\"')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds_pred = [0.8573062163538484, 0.8647515900122407, 0.8579354378082416, 0.8668245957359151, 0.8584210026934971]\nfolds = [1,2,3,4,5]\n#d = {'Score': folds_pred, 'Fold': folds}\n#df = pd.DataFrame(data=d)\nplt.figure(figsize = (10, 8), dpi = 80, facecolor = 'w', edgecolor = 'w')\nplt.scatter(folds,folds_pred,color = 'g')\nplt.axhline(y = 0.87502, color = 'r', linestyle = '-',label = \"Public score\")\nplt.xlabel('Fold')\nplt.ylabel('Public score')\nplt.title('LGBMClassifier with \"dart\" boosting')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Fitting and Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train on all data\nlgb.fit(train_no_outliers[f3] , train_no_outliers['stroke'])\n#make predictin\nprediction = lgb.predict_proba(test_d[f3])[:,1]\nsample['stroke'] = prediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.1 Feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fimp = pd.DataFrame()\ndf_fimp[\"feature\"] = train_no_outliers[f3].columns.values\ndf_fimp[\"importance\"] = lgb.feature_importances_\nplt.figure(figsize=(14, 7))\nsns.barplot(x=\"importance\", y=\"feature\", data=df_fimp.sort_values(by=\"importance\", ascending=False))\nplt.title(\"LightGBM Feature Importance\")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"bmi\" and \"age\" has significant importance in LGBMClassifier model"},{"metadata":{},"cell_type":"markdown","source":"### 5.2 Make submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('submi4.csv', index = None )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}